'use strict';

var fs = require('fs'),
    assert = require('assert'),
    async = require('async'),
    constants = require('./const');



function CdbReader(file) {
    this._file = file;
    this._filesize = 0;
    this._fd = undefined;
    this._pointers = undefined;
    this._hashtable = undefined;
    this._records = Object.create(null);
}



CdbReader.prototype.load = function (callback) {
    // Reset state
    this._pointers = undefined;
    this._hashtable = undefined;
    this._records = Object.create(null);

    // The callback receives records, but it is not a published API.
    this._buildIndex(this._readRecords.bind(this), callback);
};


CdbReader.prototype.dump = function (callback) {
    var compacted;

    if (this._pointers) {
        // We need to compact the sparse array prior to use
        // to get an accurate count
        compacted = this._pointers.filter(function compact() {
            return true;
        });

        // The total number of records matches the number of pointers, meaning
        // we must've loaded all data.
        if (Object.keys(this._records).length === compacted.length) {
            callback(null, this._records);
            return;
        }
    }

    // Yes, we re-read all data even if some keys have been loaded. In the spirit of keeping things
    // simple (until they prove to perform too slowly), we'll go with this for now.
    this.load(function (err, records) {
        var clone, key;

        if (records) {
            // Clone the record set to protected the original data
            clone = {};
            for (key in records) {
                if (Object.prototype.hasOwnProperty.call(records, key)) {
                    clone[key] = records[key];
                }
            }
        }

        callback(err, clone);
    });
};



CdbReader.prototype.find = function (key, callback) {
    this.findAll(key, function (err, values) {
        callback(err, values && values[0]);
    });
};



CdbReader.prototype.findAll = function (key, callback) {
    var that;

    if (key in this._records) {
        callback(null, this._records[key]);
        return;
    }

    that = this;

    function readRecordsForKey(hashtable, next) {
        var hash, index, slots;

        hash  = that._hashKey(key);
        index = that._getIndex(hash);
        slots = hashtable[index];

        if (slots) {
            // Sanity checking of the hashes directly doesn't work as
            // the hashes may not match but will yield the same index
            slots.forEach(function sanityCheck(slot) {
                assert.equal(that._getIndex(slot.hash), that._getIndex(hash));
            });

            async.map(slots, that._readRecord.bind(that), next);
            return;
        }

        next(null, null);
    }

    this._buildIndex(readRecordsForKey, callback);
};



CdbReader.prototype._buildIndex = function (recordReader, callback) {
    var that = this;

    async.waterfall([

        function (next) {
            fs.stat(that._file, next);
        },

        function (stats, next) {
            that._filesize = stats.size;
            fs.open(that._file, 'r', next);
        },

        function (fd, next) {
            that._fd = fd;
            that._readPointers(next);
        },

        function (pointers, next) {
            that._readHashtable(pointers, next);
        },

        // Function that takes arguments (hashtable, next)
        // The 'next' continuation should be invoked with 2 arguments (err, records)
        function (hashtable, next) {
            recordReader(hashtable, next);
        },

        function (records, next) {
            fs.close(that._fd, function (fderr) {
                // TODO - acknowledge error?
                //fderr && console.error(fderr);
                that._fd = undefined;
                next(fderr, records);
            });
        }

    ], callback);
};



CdbReader.prototype._readPointers = function (callback) {
    var that;

    if (this._pointers) {
        callback(null, this._pointers);
        return;
    }

    that = this;

    function readPointers(err, buffer) {
        var cursor, index, pointers, tuple;

        if (err) {
            callback(err);
            return;
        }

        cursor = 0;
        index = 0;
        pointers = [];

        while (cursor < buffer.length) {
            // Remember the pointer if length is non-zero and advance the cursor 8 bytes (2 * UInt32)
            tuple = that._readUInt32Tuple(buffer, cursor);
            if (tuple[1]) {
                pointers[index] = {
                    position: tuple[0],
                    length:   tuple[1]
                };
            }
            cursor += 8;
            index += 1;
        }

        callback(null, that._pointers = pointers);
    }

    this._read(0, constants.POINTER_SIZE_IN_BYTES, readPointers);
};



CdbReader.prototype._readHashtable = function (pointers, callback) {
    var that, start;

    if (this._hashtable) {
        callback(null, this._hashtable);
        return;
    }

    that = this;
    start = pointers
        .map(function (pointer) {
            return pointer.position;
        })
        .reduce(function (prev, curr) {
            return Math.min(prev, curr);
        });


    function readHashtable(err, buffer) {
        var hashtable;

        if (err) {
            callback(err);
            return;
        }

        hashtable = [];
        pointers.forEach(function (pointer, index) {
            var i, cursor, slots, tuple, descriptor;

            cursor = pointer.position - start;
            slots = pointer.length;

            for (i = 0; i < slots; i++) {
                tuple = that._readUInt32Tuple(buffer, cursor);
                if (tuple[1]) {
                    // A position is defined (non-zero), so add it the descriptor to the hashtable
                    descriptor = hashtable[index];
                    if (!descriptor) {
                        descriptor = hashtable[index] = [];
                    }

                    descriptor.push({
                        hash:     tuple[0],
                        position: tuple[1]
                    });
                }
                // Skip ahead 8 bytes (2 * UInt32)
                cursor += 8;
            }
        });

        // Sanity check (hashtable should never be larger than 256)
        assert.ok(hashtable.length <= constants.MAX_POINTERS);

        // XXX - Not sure if order of values for a single key is deterministic, but
        // trying to get a reasonable order anyway.
        hashtable = hashtable.map(function (slots) {
            return slots.reverse();
        });

        callback(null, that._hashtable = hashtable);
    }

    // Just read through the end
    this._read(start, this._filesize - start, readHashtable);
};



CdbReader.prototype._readRecords = function (hashtable, callback) {
    // TODO - This is ridiculously inefficient, but since it's a bulk operation I favored simplicity over
    // efficiency. If it's too slow or all the reads cause too much trouble it can certainly be improved.

    // Flatten and compact hashtable
    hashtable = Array.prototype.concat.apply([], hashtable);
    hashtable = hashtable.filter(function (item) {
        return item !== undefined;
    });

    var that = this;
    function complete(err) {
        callback(err, that._records);
    }

    async.eachSeries(hashtable, this._readRecord.bind(this), complete);
};



CdbReader.prototype._readRecord = function (slot, callback) {
    var that, start, length;

    // Range of a UInt32
    that = this;
    start = slot.position;
    length = 8;


    function getSizes(err, buffer) {
        var tuple, keyLength, valueLength;

        if (err) {
            callback(err);
            return;
        }

        tuple = that._readUInt32Tuple(buffer);
        keyLength = tuple[0];
        valueLength = tuple[1];

        start += length;
        length = keyLength + valueLength;

        function getValues(err, buffer) {
            var key, value;

            if (err) {
                callback(err);
                return;
            }

            key = buffer.toString('ascii', 0, keyLength);
            value = buffer.toString('ascii', keyLength);

            // Do not try to match hashes here - they may not match but will yield the same index
            assert.equal(that._getIndex(slot.hash), that._getIndex(that._hashKey(key)), 'Indices do not match.');

            (that._records[key] || (that._records[key] = [])).push(value);
            callback(null, value);
        }

        that._read(start, length, getValues);
    }

    that._read(start, length, getSizes);
};



CdbReader.prototype._hashKey = function (key) {
    var hash = constants.STARTING_HASH,
        i = 0, len = key.length;

    for (; i < len; i++) {
        hash = ((hash << 5) + hash) ^ key.charCodeAt(i);
    }

    return hash & 0xffffffff;
};



CdbReader.prototype._getIndex = function (hash) {
    // The hash value modulo 256 is the number of a hash table (e.g. bitwise AND a mask)
    // These are equivalent:
    //   hash & 0xff
    //   hash % 256
    return hash & 0xff;
};



CdbReader.prototype._read = function (position, length, callback) {
    fs.read(this._fd, new Buffer(length), 0, length, position, function (err, bytes, buffer) {
//        assert(length, buffer.length);
//        assert(bytes, buffer.length);
//        assert(bytes, length);

        // Just in case length > EOF, truncate buffer
        callback(err, buffer.slice(0, bytes));
    });
};



CdbReader.prototype._readUInt32Tuple = function (buffer, offset) {
    offset = offset || 0;
    return [ buffer.readUInt32LE(offset), buffer.readUInt32LE(offset + 4) ];
};


exports = module.exports = CdbReader;